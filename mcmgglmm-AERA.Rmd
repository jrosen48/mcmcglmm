---
title: "How engagement during out-of-school time STEM programs predicts changes in motivation in STEM"
author: "Joshua Rosenberg, Patrick Beymer, and Jennifer Schmidt  (Michigan State University)"
date: "3/2/2018"
output: html_document
---

# Abstract from proposal

Out-of-school time (OST) STEM programs have started focusing on STEM content due to the lack of individuals choosing to focus on STEM careers. Although adaptive outcomes have been found while youth are attending OST STEM programs, little research has focused on outcomes after the program has ended. Often, the goal of OST STEM programs is to increase youth’s long-term interest and competence in STEM. Therefore, examining youth interest and competence in STEM after spending time in the program is key. Framing the study around Emergent Motivation Theory (Csikszentmihalyi, 1990), we use a profile-oriented approach to investigate the relationship between youths’ momentary engagement and their interest and perceived competence at program completion. Research questions include: 1) What momentary profiles emerge? 2) What profiles are predictive of interest and perceived competence after attending an OST STEM program?

Data were collected from 203 youth in nine OST programs, each lasting four weeks. Through an Experience Sampling Method (ESM) approach, youth were signaled through mobile phones, yielding 2,463 total ESM responses. Youth were asked to complete a survey before and after the program. A two-step cluster analysis was used to identity momentary profiles. Multilevel Modeling was used to account for the nesting of momentary responses within the nine OST STEM programs. 

Four profiles were selected on the basis of fit indices, cross-validation, and concerns of parsimony and interpretability in light of theoretical accounts (See Figure 1). The profiles represent both the conditions of engagement (as indicated by students’ perceptions of challenge and skill) and the experience of engagement (as indicated by behavioral, cognitive, and affective dimensions). For subsequent analyses, the profile assignments were aggregated at the individual-level as proportions, so that each student had a value between 0 and 1 representing the proportion of their responses in each of the profiles. Results of multilevel modeling with Universally low specified as the comparison group, suggest that the proportion of youth’s responses in Skilled but not challenged and Fully engaged predicted positive and statistically significant changes in interest and competence. However, the magnitude of the effect for the relationship between Skilled but not challenged and change in interest (B = 1.01) and competence (B = 0.75) was much stronger than Fully engaged, with more modest relations with interest (B = 0.76) and competence (B = 0.55).

This study provides evidence that in the context of OST STEM programs, not only engagement, but also its conditions - perceptions of challenge and skill - foster changes in youth's interest and competence. Although spending more time in profiles with high levels of challenge, skill, and engagement was associated with positive, significant changes in interest and competence, these changes were smaller than those in the profile with more modest levels of engagement, high levels of skill, and low levels of challenge, pointing to potentially unique features of the OST context. The use of ESM in combination with a person-oriented approach helped to provide a richer and more complete understanding of outcomes from engaging experiences and their conditions.

# Background

This document outlines attempts to model relations between the engagement of youth in summer STEM programs (in-the-moment, measured using the experience sampling method) and how their engagement relates to their post-program interest in STEM. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, collapse = TRUE, warning = FALSE, message = FALSE)
```

```{r, loading-packages}
library(MCMCglmm)
library(lme4)
library(tidyverse)
```

```{r, reading-data}
d <- read_csv("new-data.csv")
# Preparing/structuring data 
ind <- distinct(d, participant_ID, post_interest)
rep <- select(d, participant_ID, rm_engagement)
type <- c(rep("s", nrow(ind)), rep("r", nrow(rep)))
dd <- data.frame(y = c(ind$post_interest, rep$rm_engagement),
                 type = as.factor(type),
                 individual = as.factor(c(as.character(ind$participant_ID), as.character(rep$participant_ID))))

d_red <- d %>% 
    group_by(participant_ID, program_ID) %>% 
    mutate(rownum = row_number()) %>% 
    mutate(post_interest = ifelse(rownum == 1, post_interest, NA))
```

# Model 0

This model uses Maximum Likelihood (ML) estimation. Note that this model does not account for the error in the predictions for engagement when relating repeated measures engagement and post interest. The first (model 0a) does not include any covariates while the second (model 0b) adds gender, under-represented minority (URM) status, and pre-interest. 

## Model 0a

```{r, model0a}
m0ai <- lmer(rm_engagement ~ 1 + (1 | participant_ID) + (1 | program_ID), data = d)
d_BLUP_1 <- ranef(m0ai) %>% 
    pluck(1) %>% 
    rownames_to_column("participant_ID") %>% 
    mutate(participant_ID = as.integer(participant_ID)) %>% 
    rename(rm_engagement_BLUP = `(Intercept)`) 

d_ind_level_1 <- distinct(d, participant_ID, post_interest, program_ID)
d_for_m1 <- left_join(d_ind_level_1, d_BLUP_1, by = "participant_ID")
d_for_m1 <- filter(d_for_m1, !is.na(post_interest))
    
m0aii <- lmer(post_interest ~ 1 + rm_engagement_BLUP + (1 | program_ID), data = d_for_m1)
```

```{r, m0a-res}
summary(m0ai)
summary(m0aii)
```

```{r, model0b}
m0bi <- lmer(rm_engagement ~ 1 + (1 | participant_ID) + (1 | program_ID), data = d)

d_BLUP_2 <- ranef(m0bi) %>% 
    pluck(1) %>% 
    rownames_to_column("participant_ID") %>% 
    mutate(participant_ID = as.integer(participant_ID)) %>% 
    rename(rm_engagement_BLUP = `(Intercept)`) 

d_ind_level_2 <- distinct(d, participant_ID, post_interest, program_ID, .keep_all = TRUE)
d_for_m2 <- left_join(d_ind_level_2, d_BLUP_2, by = "participant_ID")
d_for_m2 <- filter(d_for_m2, !is.na(post_interest))
    
m0bii <- lmer(post_interest ~ 1 + rm_engagement_BLUP + gender_female + urm + pre_interest + (1 | program_ID), data = d_for_m2)
```

```{r, m0b-res}
summary(m0bi)
summary(m0bii)
```

# Model 1 

These models use Markov Chain Monte Carlo (MCMC) estimation (via the **MCMCglmm** package). The first (model 1a) does not include any covariates while the second (model 1b) adds gender, under-represented minority (URM) status, and pre-interest. 

## Model 1a

This is a bivariate model predicting repeated measures engagement (`rm_engagement`) and post interest (`post_interest`). Two random effects are used, one for the participant random effect, and one for the program random effect. The correlation among the two outcomes is examined and appears to take on a positive, non-zero value with a 95% credible interval (slightly different from a confidence interval) that does not include zero.

```{r, m1, model1a, cache = TRUE}
prior1 =list(R =list(V =diag(c(1,0.0001),2,2), nu = 0.002, fix = 2),
             G =list(G1 =list(V =diag(2), nu = 2,
                              alpha.mu =rep(0,2),
                              alpha.V =diag(25^2,2,2)),
                     G2 =list(V =diag(2), nu = 2,
                              alpha.mu =rep(0,2),
                              alpha.V =diag(25^2,2,2))))

m1 <- MCMCglmm(cbind(rm_engagement, post_interest) ~ trait,
               random=~us(trait):participant_ID +
                   us(trait):program_ID, 
               rcov=~idh(trait):units, # this denotes response vars varying across response rows
               family = rep("gaussian",2),
               data=as.data.frame(d_red),
               prior=prior1,
               verbose=FALSE)
```

```{r, m1b-res}
summary(m1)
plot(m1)

m1_cor <- m1$VCV[,"traitpost_interest:traitrm_engagement.participant_ID"]/
    (sqrt(m1$VCV[,"traitpost_interest:traitpost_interest.participant_ID"])*
         sqrt(m1$VCV[,"traitrm_engagement:traitrm_engagement.participant_ID"]))

plot(m1_cor)
# HPDinterval(m1_cor)
posterior.mode(m1_cor)
```

# Model 2a

This model is identical to model 1a, except it adds fixed effects for a) pre-interest (the same measure as for post-interest, but given to youth before, rather than after).

```{r, model2a, cache = TRUE}
d_red <- filter(d_red,
                !is.na(gender_female) & !is.na(urm) & !is.na(pre_interest))

prior2 =list(R =list(V =diag(c(1,0.0001),2,2), nu = 0.002, fix = 2),
             G =list(G1 =list(V =diag(2), nu = 2,
                              alpha.mu =rep(0,2),
                              alpha.V =diag(25^2,2,2)),
                     G2 =list(V =diag(2), nu = 2,
                              alpha.mu =rep(0,2),
                              alpha.V =diag(25^2,2,2))))

m2 <- MCMCglmm(cbind(rm_engagement, post_interest) ~ trait + gender_female + urm + pre_interest,
               random=~us(trait):participant_ID +
                   us(trait):program_ID, 
               rcov=~idh(trait):units, # this denotes response vars varying across response rows
               family = rep("gaussian",2),
               data=as.data.frame(d_red),
               prior=prior1,
               verbose=FALSE)
```

```{r, m2b-res}
summary(m2)
plot(m2)

m2_cor <- m2$VCV[,"traitpost_interest:traitrm_engagement.participant_ID"]/
    (sqrt(m2$VCV[,"traitpost_interest:traitpost_interest.participant_ID"])*
         sqrt(m2$VCV[,"traitrm_engagement:traitrm_engagement.participant_ID"]))

plot(m2_cor)
# HPDinterval(m2_cor)
posterior.mode(m2_cor)
```

# Questions and future directions

* In the **lme4** models, we used the BLUPs in a separate linear model and obtained a regression coefficient relating repeated measures engagement to post interest, whereas in the **MCMCglmm** models we modeled the correlation of the random effects for repeated measures engagement and interest. One way to compare them is to use correlations instead of a linear model to examine the relations between the predictions (BLUPs) for repeated measures engagement and interest, but this does not allow us to account for covariates. To address this, could a partial correlation be examined (possibly using the **r2glmm** package or a manual approach)? Or, is there another way to transform the beta coefficient into a partial correlation coefficient? Or, is there a way to interpret the correlation between repeated measures engagement and post interest in the **MCMCglmm** models as a regression coefficient?